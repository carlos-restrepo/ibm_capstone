{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Tutoring Service Location Search\n",
    "\n",
    "This project serves as capstone to the IBM Data Science Professional Certificate.\n",
    "Please email any questions or comments to carlos.restrepo@live.ca.  \n",
    "Some of the cells take long to run. I would recommend running all and then reading.  \n",
    "I am assuming an internet connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the libraries and functions we will use\n",
    "\n",
    "Searching Foursquare, extracting the relevant information from the resulting JSON, and plotting points onto a Leaflet map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import folium as fol\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns= None\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import requests\n",
    "\n",
    "def foursq_search(lats, lngs, query, limit=50, radius=3000 ):\n",
    "    '''Search Foursquare at the interable coordinates [lats/lngs] given for the given [query]. \n",
    "    Return a list of jsons containing the results'''\n",
    "    res=[]\n",
    "    CLIENT_ID = 'CJZWMC5IOUH4IG4KC0KORHSJUQNEQFHS0Y5XRPOO0S1OXMCW' # your Foursquare ID\n",
    "    CLIENT_SECRET = 'VYWF405QELBRA3113JSAJMODMM4ZYIPWRFSVVZRJ1SIQ311L' # your Foursquare Secret\n",
    "    VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "    base_url= 'https://api.foursquare.com/v2/venues/search?'\n",
    "    \n",
    "    for lat, lng in zip( lats, lngs):\n",
    "        url= base_url + '&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&query={}&limit={}'.format(\n",
    "                CLIENT_ID,\n",
    "                CLIENT_SECRET,\n",
    "                VERSION,\n",
    "                lat,\n",
    "                lng,\n",
    "                radius,\n",
    "                query,\n",
    "                limit)\n",
    "        try:\n",
    "            result= requests.get(url).json()\n",
    "        except:\n",
    "            print('Error searching: {},{}. Assigning 0 venues.'.format(lat, lng))\n",
    "            result= { 'response':{} }\n",
    "        res.append(result)\n",
    "    return res\n",
    "\n",
    "def extract_results( results, amt=[], venues=[], unique_venues= [], specs= [] , excls= []):\n",
    "    '''Extract/update from each json in the list of [results] the [amt] of venues and the [unique_venues]. \n",
    "    Optionally return only venues containing a string in the [specs] list and not one in the [exclude] list.\n",
    "    Return a list with the number of venues in each result and a dataframe with the lat/lng/name of each unique venue'''\n",
    "\n",
    "    for i, result in enumerate( results ):\n",
    "        \n",
    "        if len( amt ) < len( results ): \n",
    "            amt.append( 0 )\n",
    "        \n",
    "        # non-empty result\n",
    "        if result['response'] != {}:\n",
    "                \n",
    "            # iterate through the venues in the response\n",
    "            for venue in result['response']['venues']:\n",
    "\n",
    "                # make a tuple of the lat/lng/name of each venue\n",
    "                temp_venue= ( venue['location']['lat'], venue['location']['lng'], venue['name'] )\n",
    "\n",
    "                # if the specifics list is nonempty check that at least one of the strings is in the venue name\n",
    "                # if there are specifics and they aren't in the venue name move on to the next venue\n",
    "                # similar process if a string in the inclusion list is present\n",
    "                if ( specs != [] ) & ( np.array([spec.lower() in temp_venue[2].lower() for spec in specs] ).sum() == 0): \n",
    "                    continue\n",
    "                if ( excls != [] ) & ( np.array([excl.lower() in temp_venue[2].lower() for excl in excls] ).sum() != 0): \n",
    "                    continue\n",
    "\n",
    "                amt[i]+= 1 \n",
    "                \n",
    "                # if we haven't encountered this venue, add it to our unique venue list\n",
    "                if not temp_venue in unique_venues: \n",
    "                    unique_venues+= [ temp_venue ]\n",
    "\n",
    "                    \n",
    "    return amt, unique_venues\n",
    "\n",
    "\n",
    "\n",
    "def plot_points( lats, lngs , radii=[], colors=[], labels=[], opacities=[], toner=False,zoom=12, prev_map= None):\n",
    "    '''Plot/add coordinates [lats/lngs] with optional [radii],[colors],[labels]. Optinally update a [prev_map].\n",
    "    Return a map.'''\n",
    "    \n",
    "    pt_amt= len( lats )\n",
    "    \n",
    "    # check initial conditions    \n",
    "    make_popups= lambda labels: [ fol.Popup( l, parse_html=True) for l in labels ] \\\n",
    "                                if len( labels ) == pt_amt \\\n",
    "                                else [None] * pt_amt\n",
    "    check_radii= lambda radii: radii if len( radii ) == pt_amt else [1] * pt_amt\n",
    "    check_colors= lambda colors: colors if len( colors ) == pt_amt else ['black'] * pt_amt\n",
    "    check_opacities= lambda opacities: opacities if len( opacities ) == pt_amt else [1] * pt_amt\n",
    "    \n",
    "    popups= make_popups( labels )\n",
    "    radii= check_radii( radii )\n",
    "    colors= check_colors( colors )\n",
    "    opacities= check_opacities( opacities )\n",
    "    \n",
    "    # if there was no previous map make a new one\n",
    "    if prev_map == None:\n",
    "        center= [ lats.mean(), lngs.mean() ]\n",
    "        tiles= 'Stamen Toner' if toner else 'OpenStreetMap'\n",
    "        prev_map= fol.Map( location=center, zoom_start=zoom, control_scale=True, tiles=tiles)\n",
    "        \n",
    "    for lat, lng, r, color, op, popup in zip(lats, lngs, radii, colors, opacities, popups):\n",
    "        fol.Circle(\n",
    "            location=[lat,lng],\n",
    "            radius=r,\n",
    "            color=color,\n",
    "            popup= popup,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=op\n",
    "        ).add_to(prev_map)\n",
    "\n",
    "    return prev_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import raw data from CSV\n",
    "Also remove some unnecessary rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ontario has free data\n",
    "data= pd.read_excel('https://files.ontario.ca/opendata/sif_data_table_2015_2016_en.xlsx')\n",
    "\n",
    "# drop what seem to be keys as well as irrelevant/redundant columns\n",
    "data.drop(['Board Number','Board Type','School Number', 'Province', 'Municipality','School Website','Board Website','Building Suite','P.O. Box'],axis=1,inplace=True)\n",
    "\n",
    "# title case the city column for ease\n",
    "data['City'] = data['City'].apply(lambda x: x.title())\n",
    "\n",
    "# take only english speaking elementary and secondary schools into account\n",
    "data= data[ data['School Language'] == 'English' ]\n",
    "data.drop('School Language', axis=1, inplace=True)\n",
    "\n",
    "data= data[ (data['School Level'] == 'Elementary') | (data['School Level'] == 'Secondary') ]\n",
    "data.drop('School Level', axis=1, inplace=True)\n",
    "\n",
    "print('The data has {} rows & {} cols.'.format(data.shape[0],data.shape[1]))\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up our data into the dataframe we will use\n",
    "Create a dataframe including the most useful columns from the original data, we also get rid of null values and replace them with the average for the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the columns we want\n",
    "cols= ['School Name','Enrolment','Latitude','Longitude','City']\n",
    "school_df= data[cols].copy()\n",
    "\n",
    "#these are the numerical portions of the original data\n",
    "pct_df= data.iloc[:,-5:-3]\n",
    "\n",
    "school_df= pd.concat( [school_df, pct_df], axis=1 , sort=True )\n",
    "\n",
    "# change the column names to make them easier to work with\n",
    "school_df.columns= ['school','enrol','lat','lng','city','pct_low_income', 'pct_uni_parents']\n",
    "\n",
    "# drop all entries with null in any of the specified columns\n",
    "school_df.dropna(subset= ['school','enrol','lat','lng','city'], inplace=True)\n",
    "\n",
    "# make null entries the average for the numerical data\n",
    "for col in school_df:\n",
    "    if not col in ['school', 'enrol', 'lat', 'lng' ,'city']:\n",
    "        avg= 0\n",
    "        num_entries= 0\n",
    "        for val in school_df[col].values:\n",
    "            if (not val in ['SP','N/R','N/D']) & (val == val):\n",
    "                avg+= val\n",
    "                num_entries+= 1\n",
    "        avg= avg / num_entries\n",
    "        school_df[col].replace( ['SP','N/R','N/D', np.nan], avg, inplace=True )\n",
    "\n",
    "print('The schools dataframe has {} rows & {} cols.'.format(school_df.shape[0],school_df.shape[1]))\n",
    "school_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrow our scope to Mississauga\n",
    "Some of the resulting schools were very removed from the rest so we ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missis_df= school_df[ school_df.city == 'Mississauga' ].copy()\n",
    "\n",
    "# there were some schools listed which werent _really_ in mississauga so we omit them, the school listed is the highest latitude of schools within mis\n",
    "cutoff_lat= missis_df.loc[ missis_df.school == 'Derry West Village Public School'].lat.values[0]\n",
    "missis_df= missis_df[ missis_df['lat'] <=  cutoff_lat ]\n",
    "\n",
    "# drop columns we dont need\n",
    "missis_df.drop('city', axis=1,inplace=True)\n",
    "missis_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('There are {} schools in Mississauga'.format(missis_df.shape[0]))\n",
    "missis_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search FourSquare for tutoring services near schools\n",
    "We make three searches: tutors, math and learn.\n",
    "We also filter the results to ignore irrelevant venues found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the foursquare results for searches 'tutor', 'math' and 'learn'\n",
    "\n",
    "amt= []\n",
    "unique_tutors= []\n",
    "\n",
    "print('Working.. 1/3')\n",
    "results1= foursq_search(missis_df.lat, missis_df.lng, query='tutor')\n",
    "amt, unique_tutors= extract_results(results1)\n",
    "\n",
    "print('Working.. 2/3')\n",
    "results2= foursq_search(missis_df.lat, missis_df.lng, query='math')\n",
    "amt, unique_tutors= extract_results(results2, amt=amt, unique_venues=unique_tutors, specs=['math ', 'mathematics', 'mathnasium'])\n",
    "\n",
    "print('Working.. 3/3')\n",
    "results3= foursq_search(missis_df.lat, missis_df.lng, query='learn')\n",
    "amt, unique_tutors= extract_results(results3, amt=amt, unique_venues=unique_tutors , specs=[ 'oxford', 'sylvan'])\n",
    "print('Done!')\n",
    "\n",
    "# make a column for the number of services near each school\n",
    "missis_df['tutor_services']= amt\n",
    "\n",
    "# this is a measure of how good the school is based on how many students are in it and the number of services near it\n",
    "missis_df['enrol_tutors_ratio']= missis_df.enrol / (missis_df.tutor_services + 1 )\n",
    "\n",
    "print('Results collected.')\n",
    "missis_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for the unique tutoring services\n",
    "These are the unique venues the search gave up. There are 18 in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe with the information for each unique service found\n",
    "unique_tutors_df= pd.DataFrame.from_records(unique_tutors, columns=['lat','lng','name'])\n",
    "unique_tutors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping tutors and schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tut_amt= unique_tutors_df.shape[0]\n",
    "\n",
    "# make yellow circles signifying the effective radius of each tutoring services\n",
    "area_map= plot_points( unique_tutors_df.lat, \n",
    "                         unique_tutors_df.lng,\n",
    "                         [3000] * tut_amt,\n",
    "                         ['yellow'] * tut_amt,\n",
    "                         opacities= [0.1] * tut_amt )\n",
    "\n",
    "# add the tutoring services to the map\n",
    "tut_map= plot_points( unique_tutors_df.lat, \n",
    "                         unique_tutors_df.lng,\n",
    "                         [100] * tut_amt,\n",
    "                         ['red'] * tut_amt, \n",
    "                         unique_tutors_df.name, \n",
    "                         prev_map=area_map )\n",
    "\n",
    "\n",
    "# add the schools to the map\n",
    "sch_amt= missis_df.shape[0]\n",
    "labels= [ name + ' : {} tutoring services'.format(tut) for name, tut in zip( missis_df.school, missis_df.tutor_services ) ]\n",
    "\n",
    "full_map= plot_points( missis_df.lat, \n",
    "                         missis_df.lng,\n",
    "                         [80] * sch_amt,\n",
    "                         ['blue'] * sch_amt, \n",
    "                         labels,\n",
    "                         missis_df.tutor_services / missis_df.tutor_services.max(),\n",
    "                         prev_map=tut_map )\n",
    "\n",
    "full_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K-Means Algorithm to Cluster Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a temporary dataframe to extract the data to feed the K-Means algorithm\n",
    "cols= ['school', 'lat', 'lng']\n",
    "kmeans_tempdf= missis_df.drop(cols, axis=1)\n",
    "# ensure there are no null values\n",
    "kmeans_tempdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our data to emulate a standard normal distribution to make sure all factors are equal\n",
    "X= np.nan_to_num( kmeans_tempdf.values )\n",
    "X= StandardScaler().fit_transform(X)\n",
    "print(X[:5])\n",
    "print('Data Standardized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ML model and fit it with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters= 9\n",
    "\n",
    "# run k-means on the data separated\n",
    "kmeans= KMeans(init='k-means++', n_clusters=clusters, n_init= 12)\n",
    "kmeans.fit(X)\n",
    "print('Model fit with data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've got the clusters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a column for the clusters given to each school\n",
    "missis_df['cluster']= kmeans.labels_\n",
    "missis_df[['school','cluster']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_map= [ 'red','blue','orange','black','lime','green','pink','purple','brown' ]\n",
    "\n",
    "# show the number of schools in each cluster as well as the mean ratio for each \n",
    "view= missis_df.groupby('cluster').mean().reset_index()\n",
    "view['color']= view.cluster.apply( lambda c: color_map[c].title() )\n",
    "view['count'] = missis_df.cluster.value_counts(sort=False)\n",
    "\n",
    "cols= view.columns.tolist()\n",
    "cols= cols[-2:] + [cols[-3]] + [cols[1]] + cols[4:-3]\n",
    "view= view[cols]\n",
    "\n",
    "view.columns= [ s.replace('_', ' ').title() for s in view.columns ]\n",
    "view.set_index('Color', inplace=True)\n",
    "view.index.name= None\n",
    "view.sort_values('Enrol Tutors Ratio', ascending=False ).apply( lambda x: round(x, 2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the Clustered Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avgs= missis_df.enrol_tutors_ratio\n",
    "sch_amt= missis_df.shape[0]\n",
    "labels= [ name + ' : {} naive-expected students'.format( ratio ) for name, ratio in zip( missis_df.school, avgs.apply(int) ) ]\n",
    "color_map= [ 'red','blue','orange','black','lime','green','deeppink','purple','brown' ]\n",
    "\n",
    "full_map= plot_points( missis_df.lat, \n",
    "                         missis_df.lng,\n",
    "                         50 + 200*(( avgs - avgs.min() ) / (avgs.max() - avgs.min() )),\n",
    "                         [ color_map[ cluster ] for cluster in missis_df.cluster ], \n",
    "                         labels,\n",
    "                         [0.5] * sch_amt )#, toner=True)\n",
    "\n",
    "full_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Generalization\n",
    "Here are functions generalizing the steps we took earlier, now we can repeat the process for any Ontario city we desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_df(city):\n",
    "    if isinstance(city, str):\n",
    "        city_df= school_df[ school_df.city == city ].copy()\n",
    "    elif isinstance(city, list):\n",
    "        city_df= school_df[ school_df.city == city[0] ].copy()\n",
    "        for c in city[1:]:\n",
    "            city_df= pd.concat( [ city_df, school_df[ school_df.city == c ] ], axis=0 )\n",
    "    else:\n",
    "        return None\n",
    "    # drop columns we dont need\n",
    "    city_df.drop('city', axis=1,inplace=True)\n",
    "    city_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return city_df\n",
    "\n",
    "def find_tutors(city_df, queries= ['tutor'] ):\n",
    "    # get the foursquare results for searches 'tutor', 'math' and 'learn'\n",
    "    ttl= len(queries)\n",
    "    results= []\n",
    "    for i, query in enumerate(queries):\n",
    "        print('Working.. {}/{}'.format(i + 1, ttl))\n",
    "        results.append(foursq_search(city_df.lat, city_df.lng, query=query ))\n",
    "        \n",
    "    print('Done!')\n",
    "    \n",
    "    return results\n",
    "    \n",
    "def parse_results(city_df, results, specs=[], excls=[] ):\n",
    "    ttl= len( results )\n",
    "    amt=[]\n",
    "    unique_tutors=[]\n",
    "    \n",
    "    make_empties= lambda lst: lst if len(lst) == ttl else [[]] * ttl\n",
    "        \n",
    "    specs= make_empties(specs)\n",
    "    excls= make_empties(excls)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        amt, unique_tutors= extract_results(result, amt=amt, unique_venues=unique_tutors, specs=specs[i], excls= excls[i] )\n",
    "    # make a column for the number of services near each school\n",
    "    city_df['tutor_services']= amt\n",
    "\n",
    "    # this is a measure of how good the school is based on how many students are in it and the number of services near it\n",
    "    city_df['enrol_tutors_ratio']= city_df.enrol / (city_df.tutor_services + 1 )\n",
    "    \n",
    "    unique_tutors_df= pd.DataFrame.from_records(unique_tutors, columns=['lat','lng','name'])\n",
    "\n",
    "    return city_df, unique_tutors_df\n",
    "\n",
    "def cluster_schools(city_df, clus= 9):\n",
    "    cols= ['school', 'lat', 'lng']\n",
    "    \n",
    "    X= np.nan_to_num( city_df.drop(cols, axis=1).values )\n",
    "    X= StandardScaler().fit_transform(X)\n",
    "\n",
    "    # run k-means on the data separated\n",
    "    kmeans= KMeans(init='k-means++', n_clusters=clus, n_init= 12)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # make a column for the clusters given to each school\n",
    "    city_df['cluster']= kmeans.labels_\n",
    "    \n",
    "    return city_df\n",
    "\n",
    "def map_sch_tut(city_df, unique_tutors_df, clustered=False, zoom=12, prev_map=None):\n",
    "    tut_amt= unique_tutors_df.shape[0]\n",
    "\n",
    "    area_map= plot_points( unique_tutors_df.lat, \n",
    "                             unique_tutors_df.lng,\n",
    "                             [3000] * tut_amt,\n",
    "                             ['yellow'] * tut_amt,\n",
    "                             opacities= [0.09] * tut_amt,\n",
    "                             zoom=zoom,\n",
    "                             prev_map=prev_map )\n",
    "\n",
    "    #add the tutoring services to the map\n",
    "    tut_map= plot_points( unique_tutors_df.lat, \n",
    "                             unique_tutors_df.lng,\n",
    "                             [100] * tut_amt,\n",
    "                             ['red'] * tut_amt, \n",
    "                             unique_tutors_df.name, \n",
    "                             prev_map=area_map )\n",
    "\n",
    "\n",
    "\n",
    "    sch_amt= city_df.shape[0]\n",
    "    labels= [ name + ' : {} Nearby Services'.format(tut) for name, tut in zip( city_df.school, city_df.tutor_services ) ]\n",
    "\n",
    "    if not clustered:\n",
    "        full_map= plot_points( city_df.lat, \n",
    "                                 city_df.lng,\n",
    "                                 [80] * sch_amt,\n",
    "                                 ['blue'] * sch_amt, \n",
    "                                 labels,\n",
    "                                 city_df.tutor_services / city_df.tutor_services.max(),\n",
    "                                 prev_map=tut_map )\n",
    "\n",
    "        return full_map\n",
    "    else:\n",
    "        return map_clusters(city_df, prev_map= tut_map)\n",
    "\n",
    "def map_clusters(city_df, prev_map=None):\n",
    "    avgs= city_df.enrol_tutors_ratio\n",
    "    sch_amt= city_df.shape[0]\n",
    "    labels= [ name + ' : {} Naive-expected Students : {} Nearby Services'.format( ratio, tut ) for name, ratio, tut in zip( city_df.school, avgs.apply(int), city_df.tutor_services ) ]\n",
    "    color_map= [ 'brown','blue','pink','red','purple','black','yellow','orange','green' ]\n",
    "\n",
    "    full_map= plot_points( city_df.lat, \n",
    "                             city_df.lng,\n",
    "                             50 + 200*(( avgs - avgs.min() ) / (avgs.max() - avgs.min() )),\n",
    "                             [ color_map[ cluster ] for cluster in city_df.cluster ], \n",
    "                             labels,\n",
    "                             [0.5] * sch_amt,\n",
    "                             prev_map=prev_map )\n",
    "\n",
    "    return full_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mississauga, Oakville, Brampton, Etobicoke and North York\n",
    "We will now do the quick version of our process to the combination of these cities.  \n",
    "Get the schools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities= ['Mississauga','Oakville','Brampton','Etobicoke','North York']\n",
    "city_df= get_city_df(cities)\n",
    "print('There are {} schools in '.format(city_df.shape[0]), end='')\n",
    "for i, cit in enumerate(cities):\n",
    "    print(cit, end= ' ') if cit != cities[-1] else print('& {}.'.format(cit))\n",
    "city_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for tutoring services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries= ['tutors', 'math', 'learning' ]\n",
    "results= find_tutors(city_df, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the venues:\n",
    "These contain irrelevant results, you can see 'Dr. Mathew Dentist Office' on row 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_sch_tut, services= parse_results( city_df, results )\n",
    "print('There are {} unique relevant results.'.format( len( services ) ))\n",
    "print(services.name[:5])\n",
    "city_sch_tut.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter our results:\n",
    "We look through the results and create specifications and exclusions to re-parse the results. These are done manually and could be automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs= [[], ['math ', 'mathstat', 'mathematics'], []]\n",
    "excls= [    [],\n",
    "           [ 'copy room', 'humber', 'library', 'class', 'department' ],\n",
    "           [ 'acend', 'elearning', 'e-learning' ,'playground','pavilion','disabilities',\n",
    "               'early', 'teksource', 'build','rider','network','adult',\n",
    "               'enabled', 'york','library','solutions','scotiabank',\n",
    "               'tykes','child','bmo','international','agincourt','code','engage'\n",
    "               'e-learning','music','ocadu','rbc','research','smw','ryerson',\n",
    "               'reiki','employee', 'path' ,'otf','thornhill', 'day care', 'golf', \n",
    "                'humber', 'finance','gems'] ]\n",
    "\n",
    "city_sch_tut, services= parse_results( city_df, results , specs=specs, excls=excls)\n",
    "print('There are {} unique relevant results.'.format( len( services ) ))\n",
    "print(services.name[:5])\n",
    "city_sch_tut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here are the schools and tutoring services in Toronto:\n",
    "  \n",
    "* Each blue marker represents a school.\n",
    "* Each red marker represents a tutoring service.\n",
    "* The yellow circles denote a 3km radius from each service. A 3km radius was used in our searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sch_tut(city_sch_tut, services, zoom=11 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we use KMeans to cluster the schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_sch_tut= cluster_schools(city_sch_tut)\n",
    "color_map= [ 'red','blue','orange','black','lime','green','pink','purple','brown' ]\n",
    "\n",
    "# show the number of schools in each cluster as well as the mean ratio for each \n",
    "view= city_sch_tut.groupby('cluster').mean().reset_index()\n",
    "view['color']= view.cluster.apply( lambda c: color_map[c].title() )\n",
    "view['count'] = missis_df.cluster.value_counts(sort=False)\n",
    "\n",
    "cols= view.columns.tolist()\n",
    "cols= cols[-2:] + [cols[-3]] + [cols[1]] + cols[4:-3]\n",
    "view= view[cols]\n",
    "\n",
    "view.columns= [ s.replace('_', ' ').title() for s in view.columns ]\n",
    "view.set_index('Color', inplace=True)\n",
    "view.index.name= None\n",
    "view.sort_values('Enrol Tutors Ratio', ascending=False ).apply( lambda x: round(x, 2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally here are the clustered schools along with the nearby services.\n",
    "\n",
    "Here the colours to look out for are orange and green. These schools have the least nearby services as well as the most expected students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sch_tut(city_sch_tut, services, clustered=True, zoom=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
